# ğŸŒŸ TreSRNet-Based Super-Resolution

## ğŸ¯ Overview
The **TreSRNet-based Super-Resolution** project aims to build a high-performance image super-resolution model using a **Transformer-based architecture**. This model incorporates a **Triple Attention Mechanism** (Channel Attention, Spatial Attention, and Self-Attention) to boost image qualityâ€”especially when it comes to fine detail reconstruction and accurate color preservation. By tapping into the power of Transformers, it captures both **global dependencies** and **local fine-grained details**, resulting in high-quality, high-resolution images from low-resolution inputs. ğŸ“¸âœ¨

## ğŸ—ï¸ Architecture

### 1. **RRDB (Residual-in-Residual Dense Block)**
The backbone of TreSRNet is the **Residual-in-Residual Dense Block (RRDB)**. This design combines **residual connections** and **dense connections** to improve the flow of information across the network and mitigate the vanishing gradient problem. These features help the model maintain rich feature information and converge faster during training. ğŸš€

- **Residual Connections**: Preserve previous activations for better gradient flow. ğŸ”„
- **Dense Connections**: Pass all intermediate feature maps to later layers, enriching the feature representation. ğŸ“ˆ

![RRDB Architecture](1.png)

### 2. **SR Transformer**
The **SR Transformer** is designed to use advanced **attention mechanisms**, which allows the model to learn spatial and channel-wise dependencies more effectively. By using **multi-head attention**, the model captures both **local** and **global contextual information**â€”vital for enhancing image resolution while preserving delicate details. ğŸ§

- **Channel Attention**: Focuses on the importance of each feature map. ğŸ§ 
- **Spatial Attention**: Emphasizes significant regions of the image. ğŸ—ºï¸
- **Self-Attention**: Captures long-range dependencies across the image. ğŸŒ

![SR Transformer Architecture](2.png)

### 3. **Architecture Overview**
TreSRNetâ€™s full architecture integrates **RRDB blocks** and **SR Transformer** to create a robust model capable of generating high-resolution images. The model also includes **upsampling layers** and **convolutional layers** to refine the final image output, ensuring both sharp details and smooth transitions. ğŸŒˆ

- **Upsampling Layer**: Ensures the image is scaled to the desired resolution. ğŸ“
- **Final Convolutional Layer**: Refines the image output with **Tanh activation** for pixel-perfect precision. âœ¨

![Overview of Architecture](3.png)

## ğŸ”¥ Features
- **Triple Attention Mechanism**: Combines Channel Attention, Spatial Attention, and Self-Attention for top-notch detail reconstruction and color accuracy. ğŸ¨
- **High Performance**: Achieves outstanding **PSNR** and **SSIM** scores, outperforming traditional super-resolution models. ğŸ“Š
- **Real-Time Deployment**: Optimized for real-time image enhancement, making it ideal for photo enhancements, video upscaling, and live-streaming applications. ğŸ¥âš¡
- **State-of-the-Art Architecture**: Leverages the mighty Transformer model for contextual understanding and pixel-perfect precision. ğŸ”¥

## ğŸ› ï¸ Installation

### ğŸ–¥ï¸ Prerequisites
Before diving in, make sure you have Python 3.x installed. We recommend creating a **virtual environment** to keep dependencies clean and manageable. ğŸŒ±

1. **Clone the repository**:
   ```bash
   git clone https://github.com/anthonyhuang19/TreSRNet.git
   cd TreSRNet
